# 6.1 기본 DML 튜닝

발표자: Yes
범위: 6.1
생성일시: June 20, 2022 8:30 AM
작성자: 석현임
최종편집: June 22, 2022 10:11 AM

# 6.1.1 DML 성능에 영향을 미치는 요소

- 인덱스
- 무결성 제약
- 조건절
- 서브쿼리
- Redo 로깅
- Undo 로깅
- Lock
- 커밋

**인덱스와 DML (Data Manipulation Language) 성능**

- 테이블 레코드를 입력하면, 인덱스에도 입력해야한다.
- 테이블은 Freelist를 통해 입력할 블록을 할당받지만, 인덱스는 정렬된 자료구조이므로 수직적 탐색을 통해 입력할 블록을 찾아야한다.
- 인덱스에 입력하는 과정이 더 복잡하므로 DML 성능에 미치는 영향도 크다

![Untitled](6%201%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20DML%20%E1%84%90%E1%85%B2%E1%84%82%E1%85%B5%E1%86%BC%20dc292fcc9b5f48ca987441a3990de11c/Untitled.png)

- Delete 할 떄도 마찬가지다. 테이블에서 레코드 하나를 삭제하면 인덱스 레코드 모두 찾아서 삭제해 줘야 한다.
- Update 할 때는 변경된 컬럼을 참조하는 인덱스는 정렬된 자료구조이기 때문에 인덱스만 찾아서 변경해주면 된다. (테이블에서 한 건 변경할 때마다 인덱스에는 두 개 오퍼레이션이 발생한다).
- 예를 들어 ‘A’ 를 ‘K’로 변경하면 저장 위치도 달라지므로 삭제 후 삽입하는 방식으로 처리한다.

![Untitled](6%201%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20DML%20%E1%84%90%E1%85%B2%E1%84%82%E1%85%B5%E1%86%BC%20dc292fcc9b5f48ca987441a3990de11c/Untitled%201.png)

- 핵심 트랜잭션 테이블에서 인덱스 하나라도 줄이면 TPS(Transaction Per Second)는 그만큼 향상된다.

**인덱스 개수가 DML 성능에 미치는 영향**

```sql
-- Source Table에 100만개의 레코드가 입력되어있다
-- Target 테이블은 현재 비어있다.
create table source
as
select b.no, a.*
  from (select * from emp where rownum <= 10) a
     , (select rownum as no from dual connect by level <= 100000) b;

create table target
as
select * from source where 1 = 2;

-- Target 테이블에 PK 인덱스 하나만 생성한 상태에서 Source 테이블을 읽어 레코드 100만 개를 입력
alter table target add
constraint target_pk primary key(no, empno);

set timing on;
insert into target
select * from source;

100000 개의 행이 만들어졌습니다.
경 과 : 00.00.04.95

-- 인덱스를 두 개 더 생성하고 다시 100만 건 입력
truncate table target;
create index target_x1 on target(ename);
create index target_x2 on target(deptno, mgr);
insert into target
select * from source;

100000 개의 행이 만들어졌습니다.
경 과 : 00.00.38.98
```

38.98초로 무려 여덟 배나 느려졌다. 인덱스 두개의 영향력이 이 정도로 크다.

**무결성 제약과 DML 성능**

데이터 무결성 규칙

- 개체 무결성 (Entity Integrity)
- 참조 무결성 (Referential Integrity)
- 도메인 무결성 (Domain Integrity)
- 사용자 정의 무결성 (또는 업무 제약 조건)

- DBMS에서 PK, FK, Check, Not Null같은 제약을 설정하면 더 완벽하게 데이터 무결성을 지켜낼 수 있다.
- PK, FK 제약은 Check, Not Null 제약보다 성능에 더 큰 영향을 미친다.
- Check, Not Null은 정의한 제약 조건을 준수하는지만 확인하면 되지만. PK, FK제약은 실제 데이터를 조회해 봐야 하기 때문이다.

```sql
-- 일반 인덱스 PK 제약을 모두 제거한 상태에서 100건 입력
drop index target_x1;
drop index target_x2;
alter table target drop primary key;
truncate table target;

insert into target
select * from source;

100000개의 행이 만들어졌습니다.
경 과 : 00:00:01.32
```

![Untitled](6%201%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20DML%20%E1%84%90%E1%85%B2%E1%84%82%E1%85%B5%E1%86%BC%20dc292fcc9b5f48ca987441a3990de11c/Untitled%202.png)

**조건절과 DML 성능**

```sql
set autotrace traceonly exp
update emp set sal = sal * 1.1 where deptno = 40;
```

![Untitled](6%201%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20DML%20%E1%84%90%E1%85%B2%E1%84%82%E1%85%B5%E1%86%BC%20dc292fcc9b5f48ca987441a3990de11c/Untitled%203.png)

```sql
delete from emp where deptno = 40;
```

![Untitled](6%201%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20DML%20%E1%84%90%E1%85%B2%E1%84%82%E1%85%B5%E1%86%BC%20dc292fcc9b5f48ca987441a3990de11c/Untitled%204.png)

SELECT 문과 실행계획이 다르니 않으므로 이들 DML 문에는 인덱스 튜닝 원리를 그대로 적용할 수 있다.

**서브쿼리와 DML 성능**

```sql
update emp e set sal = sal * 1.1
where exists 
   (select 'x' from dept where deptno = e.deptno and loc = 'CHICAGO');
```

![https://mblogthumb-phinf.pstatic.net/MjAyMDAyMDhfNTIg/MDAxNTgxMTI3NzI5Mjc0.IViDjy_3h3aKf7cBNViYb7C30Bj7SHv8xPUNXMmfCm4g.7GsNqMxB4LXPeLoslRvSROMX7vYaK5ZE_GaSz-GKMMwg.PNG.mirine_11/image.png?type=w800](https://mblogthumb-phinf.pstatic.net/MjAyMDAyMDhfNTIg/MDAxNTgxMTI3NzI5Mjc0.IViDjy_3h3aKf7cBNViYb7C30Bj7SHv8xPUNXMmfCm4g.7GsNqMxB4LXPeLoslRvSROMX7vYaK5ZE_GaSz-GKMMwg.PNG.mirine_11/image.png?type=w800)

```sql
delete from emp e
where exists 
  (select 'x' from dept where deptno = e.deptno and loc = 'CHICACO');
```

![https://mblogthumb-phinf.pstatic.net/MjAyMDAyMDhfMzAg/MDAxNTgxMTI3OTM3Njg3.iH4FvOkTi0bcXv1FTlaS7WwsA_-BdtThY5KR1Y77ESkg.9UzEt4oy8TGxo8u5Td8DfiKClzhpLeeCF9hWQVOPYKMg.PNG.mirine_11/image.png?type=w800](https://mblogthumb-phinf.pstatic.net/MjAyMDAyMDhfMzAg/MDAxNTgxMTI3OTM3Njg3.iH4FvOkTi0bcXv1FTlaS7WwsA_-BdtThY5KR1Y77ESkg.9UzEt4oy8TGxo8u5Td8DfiKClzhpLeeCF9hWQVOPYKMg.PNG.mirine_11/image.png?type=w800)

```sql
insert into emp
select e.*
  from emp_t e
 where exists
  (select 'x' from dept where deptno = e.deptno and loc = 'CHICAGO')
```

![https://mblogthumb-phinf.pstatic.net/MjAyMDAyMDhfMTU3/MDAxNTgxMTI4MDMzNDkw.bfaYisIWSWkUAXPygHsqj8cRw37CSBf1vsgRX37MzZwg.yQzy_nkar7Py9HkYJtJ-tKoTQXZ8Fzry91g_UC7Dlecg.PNG.mirine_11/image.png?type=w800](https://mblogthumb-phinf.pstatic.net/MjAyMDAyMDhfMTU3/MDAxNTgxMTI4MDMzNDkw.bfaYisIWSWkUAXPygHsqj8cRw37CSBf1vsgRX37MzZwg.yQzy_nkar7Py9HkYJtJ-tKoTQXZ8Fzry91g_UC7Dlecg.PNG.mirine_11/image.png?type=w800)

SELECT 문과 실행계획이 다르지 않으므로 이들 DML 문에는 4장에서 학습한 조인 튜닝 원리를 그대로 적용할 수 있다.

**Redo 로깅과 DML 성능**

- 오라클은 데이터파일과 컨트롤 파일에 가해지는 모든 변경사항을 Redo 로그에 기록한다.
- Redo 로그는 트랜잭션 데이터가 어떤 이유에서건 유실됐을 떄, 트랜잭션을 재현함으로써 유실 이전 상태로 복구하는 데 사용된다.
- DML을 수행할 떄마다 Redo 로그를 생성해야하므로 Redo 로깅은 DML 성능에 영향을 미친다.
- Redo 로그는 세가지 목적에 사용된다
    - Database Recovery
    - Cache Recovery
    - Fast Commit
    

**Undo 로깅과 DML 성능**

- 과거에는 Rollback이라는 용어를 사용했지만 오라클은 Undo라는 용어를 사용한다.
- Redo는 트랜잭션을 재현함으로써 과거를 현재 상태로 되돌리는 데 사용한다
- Undo는 트랜잭션을 롤백함으로써 현재를 과거 상태로 되돌리는 데 사용한다.

![Untitled](6%201%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20DML%20%E1%84%90%E1%85%B2%E1%84%82%E1%85%B5%E1%86%BC%20dc292fcc9b5f48ca987441a3990de11c/Untitled%205.png)

DML을 수행할 때마다 Undo를 생성해야 하므로 Undo 로깅은 DML 성능에 영향을 미친다.

**Lock과 DML 성능**

- Lock을 필요 이상으로 자주, 길게 사용하거나 레벨을 높일수록 DML 성능은 느려진다. 그렇다고 Lock을 너무 적게, 짧게 사용하거나 필요한 레벨 이하로 낮추면 데이터 품질이 나빠진다.
- 동시성 제어란 동시에 실행되는 트랜잭션 수를 최대화하면서도 입력, 수정, 삭제, 검색 시 데이터 무결성을 유지하기 위해 노력하는 것을 말한다.

**커밋과 DML 성능**

- 커밋은 DML과 별개로 실행하지만 DML을 끝내려면 커밋까지 완료해야 하므로 서로 밀접한 관련이 있다.
- DML이 Lock에 의해 블로킹된 경우, 커밋은 DML 성능과 직결된다.
- DML을 완료할 수 있게 Lock을 푸는 열쇠가 바로 커밋에 있다.
- Fast Commit을 구현하여 성능 개선을 한다.

**(1) DB 버퍼캐시**

- DB에 접속한 사용자를 대신해 보든 일을 처리하는 서버 프로세스는 버퍼캐시를 통해 데이터를 읽고 쓴다.
- 버퍼캐시에서 변경된 블록을 모아 주기적으로 데이터파일에 일괄 기록하는 작업은 DBWR 프로세스가 맡는다.

**(2) Redo 로그 버퍼**

- 버퍼캐시는 휘발성이므로 DBWR 프로세스가 Dirty 블록들을 데이터 파일에 반영할 때까지 불안한 상태라고 볼 수 있다. 하지만 버퍼캐시에 가한 변경사항을 Redo 로그에도 기록해 두었으므로 안심해도 된다.
- 버퍼캐시 데이터가 유실되더라도 Redo 로그를 이용해 언제든 복구 할 수 있기 떄문이다.
- Redo 로그도 파일이기 떄문에 디스크 I/O가 발생한다.

**(3) 트랜잭션 데이터 저장 과정**

![Untitled](6%201%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20DML%20%E1%84%90%E1%85%B2%E1%84%82%E1%85%B5%E1%86%BC%20dc292fcc9b5f48ca987441a3990de11c/Untitled%206.png)

1. DML 문을 실행하면 Redo 로그버퍼에 변경사항을 기록한다.
2. 버퍼블록에서 데이터를 변경(레코드 추가/수정/삭제)한다. 물론 버퍼캐시에서 블록을 찾지 못하면 데이터파일에서 읽는 작업부터 한다.
3. 커밋한다.
4. LGWR 프로세스가 Redo 로그버퍼 내용을 로그파일에 일괄 저장한다.
5. DBWR 프로세스가 변경된 버퍼블록들은 데이터파일에 일괄 저장한다.

- 오라클은 데이터를 변경하기 전에 항상 로그부터 기록한다. 서버 프로세스가 버퍼블록에서 데이터를 변경하기 전에 Redo 로그 버퍼에 로그를 먼저 기록한다.
- DBWR 프로세스가 Dirty 블록을 디스크에 기록하기 전에 LGWR 프로세스가 Redo 로그 파일에 로그를 먼저 기록하는 이유이기도하다. 이를 Write Ahead Logging이라고 부른다.
- 적어도 커밋시점에는 Redo 로그 버퍼 내용을 로그파일에 기록한다 ← Log Force at Commit
- 서버 프로세스가 변경한 버퍼 블록들을 디스크에 기록하지 않았더라도 커밋 시점에 Redo 로그를 디스크에 안전하게 기록했다면. 그 순간부터 트랙잭션의 영속성은 보장된다.

**(4) 커밋 = ‘저장 버튼’**

- 서버 프로세스가 그때까지 했던 작업을 디스크에 기록하라는 명령어.
- 저장을 완료할 떄까지 서버 프로세스는 다음 작업을 진행할 수 없다.
- Redo 로그버퍼에 기록된 내용을 디스크에 기록하도록 LGWR 프로세스에 신호를 보낸 후 작업을 완료했다는 신호를 받아야 다음 작업을 진행할 수 있다.
- Sync 방식이다. LGWR프로세스가 Redo 로그를 기록하는 작업은 디스크 I/O 작업이다. 커밋은 그래서 생각보다 느리다.
- 트랜잭션을 필요 이상으로 길게 정의함으로써 오랫동안 커밋하지 않는것도 문제이지만 너무 자주 커밋하는것도 문제이다.
- 오랫동안 커밋하지 않게 되면 Undo 공간이 부족해져 시스템 장애 상황을 유발할 수 있다.
- 트랜잭션을 논리적으로 잘 정의함으로써 불필요한 커밋이 발생하지 않도록 구현해야한다.

# 6.1.2 데이터베이스 Call과 성능

SQL은 3단계로 나누어 실행된다.

- Parse Call
    - SQL 파싱과 최적화를 수행하는 단계이다. SQL과 실행계획 라이브러리 캐시에서 찾으면 최적화 단계는 생략할 수 있다.
- Execute Call
    - 말그대로 SQL을 실행하는 단계이다. DML은 이 단계에서 모든 과정이 끝나지만 SELECT 문은 Fetch 단계이다.
- Fetch Call
    - 데이터를 읽어서 사용자에게 결과집합을 전송하는 과정으,로 SELECT문에서만 나타난다. 전송할 데이터가 많을 때는 Fetch Call로 나눌수 있다.

Call이 어디서 발생하느냐에 따라 User Call과 Recursive Call로 나눌수도 있다.

**User Call**

- User Call은 네트워크를 경유해 DBMS 외부로부터 인입되는 Call이다.
- 3-Tier 아키텍처에서 User Call은 WAS서버에서 발생하는 Call이다.
- DBMS 입장에서 사용자는 WAS다

**Recursive Call**

- Recursive Call은 DBMS 내부에서 발생하는 Call이다.
- SQL 파싱과 최적화 과정에서 발생하는 데이터 딕셔너리 조회, PL/SQL로 작성한 사용자 정의 함수/프로시저/트리거에 내장된 SQL을 실행할 때 발생하는 Call

User Call이든 Recusive Call이든, SQL을 실행할 떄마다 Parse, Excute, Fetch Call 단계를 거친다.

데이터베이스 Call이 많으면 성능은 느릴 수 밖에 없다. 특히, 네트워크를 경유하는 User Call이 성능에 미치는 영향은 매우 크다.

**절차적 루프 처리**

```sql
-- 테이블에 레코드 100만 개가 입력돼 있다.
create table source
as
select b.no, a.*
from (select * from emp where rownum <= 10) a,
	(select rownum as no from dual connect by level <= 100000) b;

create table target
as 
select * from source where 1 = 2;

-- PL/SQL 프로그램에서 SOURCE 테이블도 읽어 100만 번 루프를 돌면서 건건이 TARGET 테이블에 입력해보자
set timing on

begin
	for s in (select * from source)
	loop
		insert into target values ( s.no, s.empno, s.ename, 
																s.job, s.mgr, s.hiredate, 
																s.sal, s.comm, s.deptno );
	end loop;

	commit;
end;

-- 루프를 돌면서 건건이 Call이 발생했지만, 네트워크를 경유하지 않는 Recursive Call이므로 29초 만에 수행을 마쳤다
경    과 : 00:00:29:31
```

**One SQL의 중요성**

```sql
insert into target
	select * from source;

1000000 개의 행이 만들어졌습니다

경   과: 00:00:01:46
```

- 업무 로직이 복잡하면 절차적으로 처리 할 수밖에 없지만 그렇지 않다면 가급적 One SQL로 구형하려고 노력해야한다.
- 절차적으로 구현된 프로그램을 One SQL로 구현하는데 유용한 구문법
    - Insert Into Select
    - 수정가능 조인 뷰
    - Merge 문
    

# 6.1.3 Array Processing 활용

- 복잡한 업무로직을 포함할 경우 Array Proccssing 기능을 활용하면 One SQL로 구현하지 않고도 Call 부하를 줄일 수 있다.
- JAVA로 구형하였을때 218초 걸리던 프로그램이 11.8초 만에 수행을 마쳤다. 만 번에 한 번씩 INSERT 하도록 구현함으로써 백만 번 발생할 Call을 백 번으로 줄였기 때문이다.
- Call을 단 하나로 줄이지는 못하더라고 Array Processing을 활용해 10~100번 수준으로 줄일 수 있다면 One SQL에 준하는 성능 효과를 얻을 수 있다.

# 6.1.4 인덱스 및 제약 해제를 통한 대량 DML 튜닝

- 동시 트랙잭션 없이 대량 데이터를 적재하는 배치 프로그램에서는 이들 기능을 해제함으로써 큰 성능개선 효과를 얻을 수 있다.
- 1000만 건의 데이터를 입력하게 되면
    - PK 인덱스 + 일반 인덱스 존재 : 약 1분 19초
    - 인덱스 및 제약사항이 없을 경우 : 약 5.8초

**PK 제약과 인덱스 해제 1- PK 제약에 Unique 인덱스를 사용한 경우**

```sql
-- PK 제약사항 및 PK 인덱스 드랍
ALTER TABLE 테이블 MODIFY CONSTRAINT PK명 DISABLE DROP INDEX;

-- 일반 인덱스 비활성화
ALTER INDEX 인덱스명 UNUSABLE;

-- 무결성 제약과 인덱스를 해제함으로써 빠르게 INSERT할 준비
-- 1000만 건을 입력
SQL> INSERT /*+ append */ INTO target
  2  SELECT * FROM source;

1000000 개의 행이 만들어졌습니다

경   과: 00:00:05.84
SQL> commit

-- PK 제약사항 및 PK 인덱스 재생성
ALTER TABLE 테이블 MODIFY CONSTRAINT PK명 ENABLE NOVALIDATE;
경   과: 00:00:06.77

-- 일반 인덱스 활성화
ALTER INDEX 인덱스명 REBUILD;
경   과: 00:00:08.26
```

데이터 입력 시간과 제약 활성화 및 인덱스 재생성 시간을 합쳐도 기존보다 휠씬 더 빨리 작업을 마쳤다.

**PK 제약과 인덱스 해제2 -PK 제약에 Non-Unique 인덱스를 사용한 경우**

```sql
alter table target drop primary key drop index;
create index target_pk on target(no, empno); -- Non-Unique 인덱스 생성

alter table target add
constraint target_pk primary key (no, empno)
using index target_ok -- PK 제약에 Non-Unique 인덱스 사용하도록 지정
```

# 6.1.5 수정가능 조인 뷰

전통적인 방식의 UPDATE

```sql
UPDATE 고객 c
    SET  최종거래일시 = ( SELECT MAX(거래일시) FROM 거래
                           WHERE 고객번호 = c.고객번호
                           AND 거래일시 >= TRUNC(ADD_MONTHS(SYSDATE, -1)))
       , 최근거래횟수 = ( SELECT COUNT(*) FROM 거래
                           WHERE 고객번호 = c.고객번호
                           AND 거래일시 >= TRUNC(ADD_MONTHS(SYSDATE, -1)))
       , 최근거래금액 = ( SELECT SUM(거래금액) FROM 거래
                          WHERE 고객번호 = c.고객번호
                          AND 거래일시 >= TRUNC(ADD_MONTHS(SYSDATE, -1)))
   WHERE EXISTS ( SELECT 'x' FROM 거래
                    WHERE 고객번호 = c.고객번호
                    AND 거래일시 >= TRUNC(ADD_MONTHS(SYSDATE, -1)));
```

외 UPDATE 문은 아래와 같이 고칠 수 있다

```sql
UPDATE 고객 c
    SET  ( 최종거래일시,  최근거래횟수, 최근거래금액 ) =
         ( SELECT MAX(거래일시), COUNT(*), SUM(거래금액)
       FROM 거래
             WHERE 고객번호 = c.고객번호
             AND 거래일시 >= TRUNC(ADD_MONTHS(SYSDATE, -1)))
    WHERE EXISTS ( SELECT 'x' FROM 거래
                     WHERE 고객번호 = c.고객번호
                    AND 거래일시 >= TRUNC(ADD_MONTHS(SYSDATE, -1)));
```

- 한 달 이내 고객별 거래 데이터를 두 번 조회하기 떄문에 비효율이 존재한다.
- 총 고객 수와 한달 이내 거래 고객 수에 따라 성능이 좌우된다.

```sql
-- 고객 수가 아주 많다면 Exists 서브쿼리를 해시 세미 조인으로 유도하는것을 고려할 수 있다  
UPDATE 고객 c
    SET  ( 최종거래일시,  최근거래횟수, 최근거래금액 ) =
         ( SELECT MAX(거래일시), COUNT(*), SUM(거래금액)
       FROM 거래
             WHERE 고객번호 = c.고객번호
             AND 거래일시 >= TRUNC(ADD_MONTHS(SYSDATE, -1)))
    WHERE EXISTS ( SELECT /*+ unnest hash_sj */ 'x' FROM 거래
                     WHERE 고객번호 = c.고객번호
                    AND 거래일시 >= TRUNC(ADD_MONTHS(SYSDATE, -1)));
```

```sql
-- 모든 고객 레코드에 Lock이 걸리는 것은 물론 이전과 같은 값으로 갱신되는 
-- 비중이 높을수로 Redo 로그 발생량이 증가해 오히려 비효율적일 수 있다.  
UPDATE 고객 c
    SET  ( 최종거래일시,  최근거래횟수, 최근거래금액 ) =
         ( SELECT NVL(MAX(거래일시), c.최종거래일시)
                  , DECODE( COUNT(*), 0, c.최근거래횟수, COUNT(*))
                  , NVL(SUM(거래금액), c.최근거래금액)
           FROM 거래
            WHERE 고객번호 = c.고객번호
            AND 거래일시 >= TRUNC(ADD_MONTHS(SYSDATE, -1)));
```

테이블과 조인이 필요할 때 전통적인 UPDATE문을 사용하면 비효율을 완전히 해소할 수 없다.

**수정가능 조인 뷰**

수정가능 조인 뷰를 활용하면 참조 테이블과 두 번 조인하는 비효율을 없앨 수 있다.

- 조인 뷰는 FROM 절에 두 개 이상 테이블을 가진 뷰를 말한다.
- 수정 가능 조인 뷰는 말그대로 입력, 수정, 삭제가 허용되는 조인 뷰를 말한다.
- 단, 1쪽 집합과 조인하는 M쪽 집합에만 입력, 수정, 삭제가 허용된다.

```sql
  UPDATE 
    ( SELECT /*+ ordered use_hash(c) no_merge(t) */
             c.최종거래일시,  c.최근거래횟수, c.최근거래금액
              , t.거래일시,  t.거래횟수, t.거래금액
    FROM ( SELECT 고객번호, MAX(거래일시) 거래일시, COUNT(*) 거래횟수, SUM(거래금액) 거래금액
             FROM 거래
             WHERE 거래일시 >= TRUNC(ADD_MONTHS(SYSDATE, -1))
            GROUP BY 고객번호) t, 고객 c
   WHERE  c.고객번호 = t.고객번호
   )
   SET 최종거래일시 = 거래일시
     , 최근거래횟수 = 거래횟수
     , 최근거래금액 = 거래금액 ;
```

```sql
CREATE TABLE EMP AS SELECT * FROM SCOTT.EMP;
CREATE TABLE DEPT AS SELECT * FROM SCOTT.DEPT;

CREATE OR REPLACE VIEW EMP_DEPT_VIEW AS
    SELECT E.ROWID EMP_RID, E.*, D.ROWID DEPT_RID, D.DNAME, D.LOC
    FROM EMP E, DEPT D
    WHERE E.DEPTNO = D.DEPTNO;

UPDATE EMP_DEPT_VIEW SET LOC = 'SEOUL' WHERE JOB = 'CLERK'
```

```sql
     EMPNO ENAME      JOB              SAL     DEPTNO DNAME          LOC
---------- ---------- --------- ---------- ---------- -------------- -------------
      7902 FORD       ANALYST         3000         20 RESEARCH       DALLAS
      7788 SCOTT      ANALYST         3000         20 RESEARCH       DALLAS
      7934 MILLER     **CLERK**           1300         10 ACCOUNTING     NEW YORK
      7369 SMITH      **CLERK**            800         20 RESEARCH       DALLAS
      7876 ADAMS      **CLERK**           1100         20 RESEARCH       DALLAS
      7900 JAMES      **CLERK**            950         30 SALES          CHICAGO
      7782 CLARK      MANAGER         2450         10 ACCOUNTING     NEW YORK
      7566 JONES      MANAGER         2975         20 RESEARCH       DALLAS
      7698 BLAKE      MANAGER         2850         30 SALES          CHICAGO
      7839 KING       PRESIDENT       5000         10 ACCOUNTING     NEW YORK
```

- JOB이 CLERK인 사원이 10, 20, 30 부서에 모두 속해 있는데 UPDATE를 수행하고 나면 세 부서의 소재지가 모두 SEOUL로 바뀔 것이다.
- 다른 job을 가진 사원의 부서 소재지까지 바뀌게 된다.

```sql
UPDATE EMP_DEPT_VIEW SET COMM = NVL(COMM, 0) + (SAL * 0.1) WHERE SAL <= 1500;
                         
--1행에 오류:
-- 키-보존된것이 아닌 테이블로 대응한 열을 수정할 수 없습니다
--ORA-01779: Connon modify a column witch maps to a non key-preserved table

DELETE FROM EMP_DEPT_VIEW WHERE JOB = 'CLERK'
           
--1행에 오류:
-- 뷰으로 부터 정확하게 하나의 키-보전된 테이블 없이 삭제할 수 없습니다
-- ORA-01752: cannot delete from view without exactly one key-preserved table
-- 옵티마이져가 지금 어느 테이블이 1쪽 집합인지 알 수 없기 떄문에 발생하는 오류이다.

-- 1쪽 집합에 PK 제약을 설정하거나 Unique 인덱스를 생성해야 수정가능 조인뷰를 통한 입력/ 수정/ 삭제가 가능하다
ALTER TABLE DEPT ADD CONSTRAINT DEPT_PK PRIMARY KEY(DEPTNO);
UPDATE EMP_DEPT_VIEW SET COMM = NVL(COMM, 0) + (SAL * 0.1) WHERE SAL <= 1500;

```

PK 제약을 설정하면 EMP 테이블은 ‘키-보존 테이블(Key-Preserved Table)이 되고, DEPT 테이블은 ‘비 키-보존 테이블(Non Key-Preserved Table)로 남는다.

**키 보존 테이블이란?**

- 조인된 결과집합을 통해서도 중복 값 없이 Unique 하게 식별이 가능한 테이블.
- Unique한 1쪽 집합과 조인되는 테이블이어야 조인된 결과집합을 통한 식별이 가능하다.

```sql
SQL> SELECT ROWID, EMP_RID, DEPT_RID, EMPNO, DEPTNO FROM EMP_DEPT_VIEW;

ROWID              EMP_RID            DEPT_RID                EMPNO     DEPTNO
------------------ ------------------ ------------------ ---------- ----------
AAANM6AABAAAOxaAAA AAANM6AABAAAOxaAAA AAANM7AABAAAOxiAAB       7369         20
AAANM6AABAAAOxaAAB AAANM6AABAAAOxaAAB AAANM7AABAAAOxiAAC       7499         30
AAANM6AABAAAOxaAAC AAANM6AABAAAOxaAAC AAANM7AABAAAOxiAAC       7521         30
AAANM6AABAAAOxaAAD AAANM6AABAAAOxaAAD AAANM7AABAAAOxiAAB       7566         20
AAANM6AABAAAOxaAAE AAANM6AABAAAOxaAAE AAANM7AABAAAOxiAAC       7654         30
AAANM6AABAAAOxaAAF AAANM6AABAAAOxaAAF AAANM7AABAAAOxiAAC       7698         30
AAANM6AABAAAOxaAAG AAANM6AABAAAOxaAAG AAANM7AABAAAOxiAAA       7782         10
AAANM6AABAAAOxaAAH AAANM6AABAAAOxaAAH AAANM7AABAAAOxiAAB       7788         20
AAANM6AABAAAOxaAAI AAANM6AABAAAOxaAAI AAANM7AABAAAOxiAAA       7839         10
AAANM6AABAAAOxaAAJ AAANM6AABAAAOxaAAJ AAANM7AABAAAOxiAAC       7844         30
AAANM6AABAAAOxaAAK AAANM6AABAAAOxaAAK AAANM7AABAAAOxiAAB       7876         20
AAANM6AABAAAOxaAAL AAANM6AABAAAOxaAAL AAANM7AABAAAOxiAAC       7900         30
AAANM6AABAAAOxaAAM AAANM6AABAAAOxaAAM AAANM7AABAAAOxiAAB       7902         20
AAANM6AABAAAOxaAAN AAANM6AABAAAOxaAAN AAANM7AABAAAOxiAAA       7934         10
```

- dept_rid에 중복 값이 나타나고 있다. emp_rid에서는 중복 값이 없으며 뷰의 rowid와 일치한다.
- **키 보존 테이블이란 뷰에 rowid를 제공하는 테이블이다**

**ORA-01779 오류 회피**

```sql
UPDATE
   (SELECT D.DEPTNO, D.AVG_SAL D_AVG_SAL, E.AVG_SAL E_AVG_SAL
   FROM (SELECT DEPTNO, ROUND(AVG(SAL), 2) AVG_SAL FROM EMP GROUP BY DEPTNO) E
         , DEPT D
   WHERE D.DEPTNO = E.DEPTNO)
   SET D_AVG_SAL = E_AVG_SAL;
SET D_AVG_SAL = E_AVG_SAL
```

- 11g 이하 버전에서 위 UPDATE 문을 실행하면 ORA-01779 에러가 발생한다.
- EMP 테이블을 DEPTNO로 Group By 했으므로 DEPTNO 컬럼으로 조인한 DEPT 테이블은 키가 보존되는데도 옵티마이저가 불필요한 제약을 가한 것이다.

- 10g에선 bypass_ujvc 힌트를 사용해 제약을 회피할 수 있었다.
- Updageable Join View Check를 생략하라고 옵티마이저에 지시하는 힌트다.
- 11g 부터 이 힌트를 사용할 수 없게 되어 MERGE문으로 변경해줘야 한다

# 6.1.6 MERGE 문 활용

- DW에서 가장 흔히 발생하는 오퍼레이션은 기간계 시스템에서 가져온 신규 트랜잭션 데이트를 반영함으로써 두 시스템 간 데이터를 동기화하는 작업이다.
1. 전일 발생한 변경 데이터를 기간계 시스템으로부터 추출
2. CUSTOMER_DELTA 테이블을 DW 시스템으로 전송
3. DW 시스템으로 적재

```sql
MERGE INTO customer t USING customer_delta s ON (t.cust_id = s.cust_id)
WHEN MATCHED THEN UPDATE
  SET t.cust_id = s.cust_id, t.cust_nm = s.cust_nm, t.email = s.email, ...
WHEN NOT MATCHED THEN INSERT
  (cust_id, cust_nm, email, tel_no, region, addr, reg_dt) VALUES
  (s.cust_id, s.cust_nm, s.email, s.tel_no, s.region, s.addr, s.reg_dt);
```

- Target 테이블과 Left Outer 방식으로 조인해서 조인에 성공하면 UPDATE, 실패하면 INSERT 한다.

**Optional Clauses**

```sql
MERGE INTO customer t USING customer_delta s ON (t.cust_id = s.cust_id)
WHEN MATCHED THEN UPDATE
  SET t.cust_id = s.cust_id, t.cust_nm = s.cust_nm, t.email = s.email, ...;

MERGE INTO customer t USING customer_delta s ON (t.cust_id = s.cust_id)
WHEN NOT MATCHED THEN INSERT
  (cust_id, cust_nm, email, tel_no, region, addr, reg_dt) VALUES
  (s.cust_id, s.cust_nm, s.email, s.tel_no, s.region, s.addr, s.reg_dt);

-- Merge문으로 수정 가능 조인 뷰의 기능을 대체
MERGE INTO dept d
USING (select deptno, round(avg(sal), 2) avg_sal from emp group by deptno) e
ON (d.deptno = e.deptno)
WHEN MATCHED THEN UPDATE set d.avg_sal = e.avg_sal;
```

**Conditional Clauses**

ON절에 기술한 조인문외에 추가로 조건절을 기술할 수 있다.

```sql
MERGE INTO customer t USING customer_delta s ON (t.cust_id = s.cust_id)
WHEN MATCHED THEN UPDATE
  SET t.cust_id = s.cust_id, t.cust_nm = s.cust_nm, t.email = s.email, ...
  WHERE reg_dt >= to_char('20000101','yyyymmdd')
WHEN NOT MATCHED THEN INSERT
  (cust_id, cust_nm, email, tel_no, region, addr, reg_dt) VALUES
  (s.cust_id, s.cust_nm, s.email, s.tel_no, s.region, s.addr, s.reg_dt)
  WHERE reg_dt < trunc(sysdate) ;
```

**Delete Clauses**

Merge문을 이용하여 이미 저장된 데이터를 조건에 따라 지울 수 있다.

Update가 이루어진 결과로서 탈퇴일자가 null이 아닌 레코드만 삭제된다. 탈퇴일자가 null이 아니었어도 merge문을 수행한 결과가 null이면 삭제되지 않는다.

```sql
MERGE INTO customer t USING customer_delta s ON (t.cust_id = s.cust_id)
WHEN MATCHED THEN UPDATE
  SET t.cust_id = s.cust_id, t.cust_nm = s.cust_nm, t.email = s.email, ...
  DELETE WHERE t.withdraw_dt is not null --탈퇴일시가 null이 아닌 레코드 삭제
WHEN NOT MATCHED THEN INSERT
  (cust_id, cust_nm, email, tel_no, region, addr, reg_dt) VALUES
  (s.cust_id, s.cust_nm, s.email, s.tel_no, s.region, s.addr, s.reg_dt);
```

**Merge into 활용 예**

1. SQL 수행 빈도 개선
    - 저장하려는 레코드가 기존에 있던 것이면 update를 수행하고, 그렇지 않을 insert를 수행하는 경우, SQL이 항상 두번씩 수행 된다.
    - Merge문을 활용하면 SQL이 한번만 수행된다
2. 논리 I/O발생을 감소하여 SQL 수행 속도 개선